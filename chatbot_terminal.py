import os
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from dotenv import load_dotenv

# Carrega variÃ¡veis de ambiente do .env
load_dotenv()

# Inicializa o modelo da Groq usando a API OpenAI-compatible
chat = ChatOpenAI(
    temperature=0.7,
    model="llama3-8b-8192",  # ou outro modelo disponÃ­vel na Groq
    api_key=os.getenv("GROQ_API_KEY"),
    base_url="https://api.groq.com/openai/v1"
)

# Mensagens de contexto
mensagens = [
    SystemMessage(content="VocÃª Ã© um assistente Ãºtil e direto.")
]

# Loop do terminal
print("ğŸ¤– Chatbot iniciado! (digite 'sair' para encerrar)\n")

while True:
    entrada = input("VocÃª: ")
    if entrada.lower() in ["sair", "exit", "quit"]:
        print("ğŸ‘‹ AtÃ© mais!")
        break

    mensagens.append(HumanMessage(content=entrada))
    resposta = chat.invoke(mensagens)
    mensagens.append(resposta)
    print(f"Bot: {resposta.content}\n")

